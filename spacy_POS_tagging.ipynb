{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"file_path\", encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#for parsed_doc in nlp.pipe(iter(df['Text']), batch_size=1, n_threads=4):\n",
    "#print (parsed_doc[0].text, parsed_doc[0].tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time     #parsing and extraction code\n",
    "\n",
    "df['Parsed'] = df['sents'].apply(nlp)\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "start = time.time()\n",
    "words, doc_toks = [] , [] \n",
    "df['Parsed'] = df[' dataframe_header_name??'].apply(nlp)\n",
    "\n",
    "for doc in df['Parsed']:\n",
    "  x = doc[0].tag_ \n",
    "  word_token , tok_tag= [], []\n",
    "  for token in doc:    \n",
    "    word_token.append(token)\n",
    "    tok_tag.append(token.tag_)\n",
    "  words.append(word_token)\n",
    "  doc_toks.append(tok_tag)\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "print (time.time() - start)\n",
    "\n",
    "\n",
    "\n",
    "print (tok.tag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = pd.DataFrame(np.column_stack([words, doc_toks,]), \n",
    "                               columns=['sentence', 'token_tags'])\n",
    "\n",
    "\n",
    "file_name.to_csv('file_name')\n",
    "!cp file_name.csv \"gdrive_path\" \n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "files.download('file_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
