{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stop=set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our additions to the stop words, you can edit \n",
    "stop = set(list(stop) + [\"http\",\"https\", \"@\", ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import counterfactual training set and view basic info\n",
    "\n",
    "cf_train = pd.read_csv(\"filepath_here\",encoding = 'choose your encoding_ optional')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more info about the dataset \n",
    "print(cf_train.info())\n",
    "print(cf_train.head())\n",
    "print(\n",
    ")\n",
    "classes= cf_train.gold_label                 #Will show up null values, and the number of each of the \n",
    "                                               #different label classes present\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratio of counterfactuals/non-counterfactuals\n",
    "\n",
    "ratio_cf = [1454/11546]\n",
    "print (\"Ratio of Cf to non-Cf: \",ratio_cf)     #just grabbing the actual numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='gold_label', data=cf_train)        #a lot more zeros than ones, but nothing to worry about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Going down the insight rabbit hole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-Number of words in each Sentence\")\n",
    "\n",
    "def to_plot(_gold_label):\n",
    "    return cf_train[cf_train['gold_label']==_gold_label]['sentence'].str.split().map(lambda x: len(x))\n",
    "def how_to_plot(**kwargs):\n",
    "    ax1.hist(cf_train_len,**kwargs)\n",
    "def show_word_distrib(gold_label=0, field=\"sentence\"):\n",
    "    txt = cf_train[cf_train['gold_label']==gold_label][field].str.lower().str.replace(r'\\|', ' ').str.cat(sep=' ')\n",
    "    words = nltk.tokenize.word_tokenize(txt)\n",
    "    words_except_stop_dist = nltk.FreqDist(w for w in words if w not in stop) \n",
    "    \n",
    "    rslt = pd.DataFrame(words_except_stop_dist.most_common(top_N),\n",
    "                        columns=['Word', 'Frequency']).set_index('Word')\n",
    "    print(rslt)\n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "    rslt.plot.bar(figsize=(30,10))\n",
    "\n",
    "print(\"-Average word length \")\n",
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
    "word=cf_train[cf_train['gold_label']==1]['sentence'].str.split().apply(lambda x : [len(i) for i in x])\n",
    "sns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='red')\n",
    "ax1.set_title('Non-counterfactuals')\n",
    "\n",
    "word=cf_train[cf_train['gold_label']==0]['sentence'].str.split().apply(lambda x : [len(i) for i in x])\n",
    "sns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='green')\n",
    "ax2.set_title('Counterfactuals')\n",
    "fig.suptitle('Average word length')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-Word distribution\")\n",
    "\n",
    "top_N = 30\n",
    "\n",
    "print(\"-- Counterfactuals\")\n",
    "\n",
    "show_word_distrib(gold_label=1, field=\"sentence\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-- Non Counterfactuals\")\n",
    "\n",
    "show_word_distrib(gold_label=0, field=\"sentence\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the word frequency chart might make more sense if we get rid of the punctuation...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#we seperate the sentences into positive and negative counterfactuals and see if we can find a clearer pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sentences = cf_train.loc[cf_train['gold_label'] == 0]\n",
    "cf_neg = negative_sentences.sentence\n",
    "cf_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_sentences = cf_train.loc[cf_train['gold_label'] == 1]\n",
    "cf_pos = positive_sentences.sentence\n",
    "cf_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a little cleaning using regex, We dont get rid of capitals  \n",
    "\n",
    "processed = cf_pos.str.replace(r'^,+@[^\\,],*\\,[a-z]{2,}$', 'email')  \n",
    "\n",
    "cf_pos_proc = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\,]+\\,[a-zA-Z]{2,3}(/\\S*)?$', 'website')\n",
    "\n",
    "cf_pos_proc = processed.str.replace(r'£|\\$', 'cashsign')\n",
    "\n",
    "cf_pos_proc = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$','phnumber')\n",
    "                                  \n",
    "cf_pos_proc = processed.str.replace(r'\\d+(\\.\\d+)?', 'number')\n",
    "\n",
    "\n",
    "\n",
    "print(cf_pos_proc[:20])\n",
    "\n",
    "\n",
    "processed = cf_pos.str.replace(r'^,+@[^\\,],*\\,[a-z]{2,}$', 'emilad')  \n",
    "\n",
    "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\,]+\\,[a-zA-Z]{2,3}(/\\S*)?$', 'wbadd')\n",
    "\n",
    "processed = processed.str.replace(r'£|\\$', 'cshsgn')\n",
    "\n",
    "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$','pnumbr')\n",
    "                                  \n",
    "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'nber')\n",
    "\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]','')#punctuation\n",
    "\n",
    "processed = cf_pos_proc\n",
    "\n",
    "\n",
    "print(cf_pos_proc[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " positive_sentences.sentence = cf_pos_proc \n",
    "    \n",
    "    \n",
    "def show_word_distrib(gold_label=0, field=\"sentence\"):\n",
    "    txt = positive_sentences[positive_sentences['gold_label']==gold_label][field].str.lower().str.replace(r'\\|', ' ').str.cat(sep=' ')\n",
    "    words = nltk.tokenize.word_tokenize(txt)\n",
    "    words_except_stop_dist = nltk.FreqDist(w for w in words if w not in stop) \n",
    "    \n",
    "    rslt = pd.DataFrame(words_except_stop_dist.most_common(top_N),\n",
    "                        columns=['Word', 'Frequency']).set_index('Word')\n",
    "    print(rslt)\n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "    rslt.plot.bar(figsize =(30,10))\n",
    "    \n",
    "    print(\"-Word distribution\")\n",
    "\n",
    "top_N = 30\n",
    "\n",
    "print(\"-- Counterfactuals\")\n",
    "\n",
    "show_word_distrib(gold_label=1, field=\"sentence\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n't= not, 'd replace were lost, but they are very valid parts of the dat set. can we replace 'd with could,should and would?''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets do the same for the negative sentences\n",
    "nprocessed = cf_neg.str.replace(r'^,+@[^\\,],*\\,[a-z]{2,}$', 'email')  \n",
    "\n",
    "cf_neg_proc = nprocessed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\,]+\\,[a-zA-Z]{2,3}(/\\S*)?$', 'website')\n",
    "\n",
    "cf_neg_proc = nprocessed.str.replace(r'£|\\$', 'cashsign')\n",
    "\n",
    "cf_neg_proc = nprocessed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$','phnumber')\n",
    "                                  \n",
    "cf_neg_proc = nprocessed.str.replace(r'\\d+(\\.\\d+)?', 'number')\n",
    "\n",
    "cf_neg_proc = nprocessed.str.replace(r'[^\\w\\d\\s]','')#punctuation\n",
    "\n",
    "\n",
    "cf_neg.head\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " negative_sentences.sentence = cf_neg_proc \n",
    "    \n",
    "    \n",
    "def show_word_distrib(gold_label=0, field=\"sentence\"):\n",
    "    txt = negative_sentences[negative_sentences['gold_label']==gold_label][field].str.lower().str.replace(r'\\|', ' ').str.cat(sep=' ')\n",
    "    words = nltk.tokenize.word_tokenize(txt)\n",
    "    words_except_stop_dist = nltk.FreqDist(w for w in words if w not in stop) \n",
    "    \n",
    "    rslt = pd.DataFrame(words_except_stop_dist.most_common(top_N),\n",
    "                        columns=['Word', 'Frequency']).set_index('Word')\n",
    "    print(rslt/8)\n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "    rslt.plot.bar(figsize =(30,10))\n",
    "    \n",
    "    print(\"-Word distribution\")\n",
    "\n",
    "top_N = 30\n",
    "\n",
    "\n",
    "\n",
    "print(\"-- Non Counterfactuals\")\n",
    "\n",
    "show_word_distrib(gold_label=0, field=\"sentence\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
